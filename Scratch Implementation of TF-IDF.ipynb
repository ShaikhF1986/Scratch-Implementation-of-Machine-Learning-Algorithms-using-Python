{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XLaGFUMxLiy"
   },
   "source": [
    "## tfidf implementation from scratch\n",
    "\n",
    "\n",
    "$IDF(t) = \\log_{e}\\frac{\\text{Total  number of documents}} {\\text{Number of documents with term t in it}}.$\n",
    "\n",
    "$IDF(t) = \\log_{e}\\frac{\\text{Total  number of documents}} {\\text{Number of documents with term t in it}+1}.$\n",
    "</li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnV82tg1xLi0"
   },
   "source": [
    "### Data Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUsYm9wjxLi1"
   },
   "outputs": [],
   "source": [
    "## SkLearn# Collection of string documents\n",
    "\n",
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLwmFZfKxLi4"
   },
   "source": [
    "### SkLearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Np4dfQOkxLi4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(data)\n",
    "skl_output = vectorizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_output[0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7Om8YpYxLi6",
    "outputId": "0a3bd0f5-4424-4400-944f-4482a80bd799"
   },
   "outputs": [],
   "source": [
    "# sklearn feature names, they are sorted in alphabetic order by default.\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTKplK96xLi-",
    "outputId": "53722fa2-6756-4aa0-f179-37b578bb6890"
   },
   "outputs": [],
   "source": [
    "# Here we will print the sklearn tfidf vectorizer idf values after applying the fit method\n",
    "# After using the fit function on the corpus the vocab has 9 words in it, and each has its idf value.\n",
    "\n",
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CTiWHygxLjA",
    "outputId": "8d5a9cde-2c29-4afe-f7b4-1547e88dba4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of sklearn tfidf vectorizer output after applying transform method.\n",
    "\n",
    "skl_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDKEpbA-xLjD",
    "outputId": "87dafd65-5313-443f-8c6e-1b05cc8c2543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n"
     ]
    }
   ],
   "source": [
    "# sklearn tfidf values for first line of the above corpus.\n",
    "# Here the output is a sparse matrix\n",
    "\n",
    "print(skl_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QWo34hexLjF",
    "outputId": "cdc04e08-989f-4bdc-dd7f-f1c82a9f90be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn tfidf values for first line of the above corpus.\n",
    "# To understand the output better, here we are converting the sparse output matrix to dense matrix and printing it.\n",
    "# Notice that this output is normalized using L2 normalization. sklearn does this by default.\n",
    "\n",
    "print(skl_output[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfIwx5LzxLjI"
   },
   "source": [
    "### Our custom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjuCcJwXxLjJ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating tf for the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the term frequency\n",
    "def termFrequency(data):\n",
    "    tf = []\n",
    "    for l in data:\n",
    "        line = l.split(\" \")\n",
    "        v = Counter(line)\n",
    "        tfr = {}\n",
    "        for k in v.keys():\n",
    "            tfr[k] = v[k]/len(line)\n",
    "        tf.append(tfr)\n",
    "    return tf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calidf(data):\n",
    "    cin ={} #it will store the in how many documents a particular word occures\n",
    "    \n",
    "    unique = []\n",
    "    for line in data:\n",
    "        for word in line.split(\" \"):\n",
    "            if word not in unique:\n",
    "                unique.append(word)\n",
    "            else:\n",
    "                continue\n",
    "    idf = {}\n",
    "    for word in unique:\n",
    "        count = 0\n",
    "        for line in data:\n",
    "            for w in line.split(\" \"):\n",
    "                if word in w:\n",
    "                    count = count+1\n",
    "        idf[word] = 1 + math.log((1+len(data))/(1+count),2.71) \n",
    "    return idf       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data,tf,idf):\n",
    "    #tf = termFrequency(data)\n",
    "    #idf = calidf(data)\n",
    "    tfidf = []\n",
    "    for i,line in enumerate(data):\n",
    "        d = {}\n",
    "        for word in line.split(\" \"):\n",
    "            if word in idf.keys():\n",
    "                d[word] = tf[i][word]*idf[word]\n",
    "        for word in idf.keys():\n",
    "            if word not in d.keys():\n",
    "                d[word] = 0\n",
    "        tfidf.append(d)\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "    tfidf = vec.fit_transform(tfidf)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data):\n",
    "    ##unique word in every document\n",
    "    unique = []\n",
    "    for line in data:\n",
    "        for word in line.split(\" \"):\n",
    "            if word not in unique:\n",
    "                unique.append(word)\n",
    "            else:\n",
    "                continue\n",
    "    ##calculating the idf for each word\n",
    "    idf = {}\n",
    "    for word in unique:\n",
    "        count = 0\n",
    "        for line in data:\n",
    "            for w in line.split(\" \"):\n",
    "                if word in w:\n",
    "                    count = count+1\n",
    "        ##calculating the idf for the word given in the training set\n",
    "        idf[word] = 1 + math.log((1+len(data))/(1+count),2.71)\n",
    "    ##calculating the term frequency\n",
    "    tf = []\n",
    "    for l in data:\n",
    "        line = l.split(\" \")\n",
    "        v = Counter(line)\n",
    "        tfr = {}\n",
    "        for k in v.keys():\n",
    "            tfr[k] = v[k]/len(line)\n",
    "        tf.append(tfr)\n",
    "    return [tf,idf] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['this is the first document','this document is the second document','and this is the third one','is this the first document',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf,idf = fit(corpus)   #calculating the tf, idf from the training data\n",
    "d = transform(corpus,tf,idf)  ##we need to provide the data corpus that we want to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.2       , 0.30247782, 0.08208286, 0.        ,\n",
       "        0.        , 0.2       , 0.        , 0.2       ],\n",
       "       [0.        , 0.33333333, 0.        , 0.06840238, 0.        ,\n",
       "        0.3198492 , 0.16666667, 0.        , 0.16666667],\n",
       "       [0.3198492 , 0.        , 0.        , 0.06840238, 0.3198492 ,\n",
       "        0.        , 0.16666667, 0.3198492 , 0.16666667],\n",
       "       [0.        , 0.2       , 0.30247782, 0.08208286, 0.        ,\n",
       "        0.        , 0.2       , 0.        , 0.2       ]])"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['this', 'is', 'the', 'first', 'document', 'second', 'and', 'third', 'one'])"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## features in the tfidf\n",
    "idf.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf with k number of features based on idf values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calidf(data,n_features):\n",
    "    cin ={} #it will store the in how many documents a particular word occures\n",
    "    \n",
    "    unique = []\n",
    "    for line in data:\n",
    "        for word in line.split(\" \"):\n",
    "            if word not in unique:\n",
    "                unique.append(word)\n",
    "            else:\n",
    "                continue\n",
    "    idf = {}\n",
    "    for word in unique:\n",
    "        count = 0\n",
    "        for line in data:\n",
    "            for w in line.split(\" \"):\n",
    "                if word in w:\n",
    "                    count = count+1\n",
    "        idf[word] = math.log10((len(data))/(count))\n",
    "    ### sorting the dictionary to extract the top features\n",
    "    idf1 = {k: v for k, v in sorted(idf.items(), key=lambda item: item[1])}\n",
    "    return idf1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data,n_features):\n",
    "    cin ={} #it will store the in how many documents a particular word occures\n",
    "    ##finding the unique words in the each document\n",
    "    unique = []\n",
    "    for line in data:\n",
    "        for word in line.split(\" \"):\n",
    "            if word not in unique:\n",
    "                unique.append(word)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    idf = {}\n",
    "    #calculating the idf for each word that is available in the sentence as well as training set\n",
    "    for word in unique:\n",
    "        count = 0\n",
    "        for line in data:\n",
    "            for w in line.split(\" \"):\n",
    "                if word in w:\n",
    "                    count = count+1\n",
    "        idf[word] =1 + math.log((1+len(data))/(1+count),2.71)\n",
    "    ##sorting the keys according to idf value\n",
    "    idf1 = {k: v for k, v in sorted(idf.items(), key=lambda item: item[1])}\n",
    "    #print(idf1)\n",
    "    ## extracting first n_features from the dictionary\n",
    "    key,value = [],[]\n",
    "    for k in idf1.keys():\n",
    "        key.append(k)\n",
    "        value.append(idf1[k])\n",
    "    l = -1\n",
    "    idf2 = {}\n",
    "    for i in range(n_features):\n",
    "        idf2[key[l]] = value[l]\n",
    "        l=l-1\n",
    "\n",
    "    #calcualting term-frequency    \n",
    "    tf = []\n",
    "    for l in data:\n",
    "        line = l.split(\" \")\n",
    "        v = Counter(line)\n",
    "        tfr = {}\n",
    "        for k in v.keys():\n",
    "            tfr[k] = v[k]/len(line)\n",
    "        tf.append(tfr)\n",
    "    ##returning the idf and tf for the feature transformation\n",
    "    return [tf,idf2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data,tf,idf):\n",
    "    #tf = termFrequency(data)\n",
    "    #idf = calidf(data)\n",
    "    tfidf = []\n",
    "    for i,line in enumerate(data):\n",
    "        d = {}\n",
    "        for word in line.split(\" \"):\n",
    "            if word in idf.keys():\n",
    "                d[word] = tf[i][word]*idf[word]\n",
    "        for word in idf.keys():\n",
    "            if word not in d.keys():\n",
    "                d[word] = 0\n",
    "        tfidf.append(d)\n",
    "    vec = DictVectorizer(sparse=True)\n",
    "    tfidf = vec.fit_transform(tfidf)\n",
    "    nor = normalize(tfidf)\n",
    "    #tfidf = nor.fit_transform(tfidf)\n",
    "    return nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5  #please provide how many features u want to use\n",
    "tf,idf = fit(corpus,n_features)   #calculating the tf, idf from the training data\n",
    "d = transform(corpus,tf,idf)  ##we need to provide the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features :  dict_keys(['one', 'third', 'and', 'second', 'first'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Features : \",idf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['one', 'third', 'and', 'second', 'first'])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
       "        [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the data from the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(\"cleaned_strings\", \"rb\")) as openfile:\n",
    "            data = (pickle.load(openfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 50 #please provide how many features u want to use\n",
    "tf,idf = fit(data,n_features)   #calculating the tf, idf from the training data\n",
    "d = transform(data,tf,idf)  ##we need to provide the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 50 features based on idf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exceptionally': 6.941046305978266,\n",
       " 'regrettable': 6.941046305978266,\n",
       " 'virtue': 6.941046305978266,\n",
       " 'clothes': 6.941046305978266,\n",
       " 'jessice': 6.941046305978266,\n",
       " 'faster': 6.941046305978266,\n",
       " 'bonding': 6.941046305978266,\n",
       " 'smoothly': 6.941046305978266,\n",
       " 'flowed': 6.941046305978266,\n",
       " 'anyway': 6.941046305978266,\n",
       " 'hollander': 6.941046305978266,\n",
       " 'darren': 6.941046305978266,\n",
       " 'flaming': 6.941046305978266,\n",
       " 'trysts': 6.941046305978266,\n",
       " 'houses': 6.941046305978266,\n",
       " 'clients': 6.941046305978266,\n",
       " 'salesman': 6.941046305978266,\n",
       " 'estate': 6.941046305978266,\n",
       " 'gay': 6.941046305978266,\n",
       " 'obsessed': 6.941046305978266,\n",
       " 'sex': 6.941046305978266,\n",
       " 'weaving': 6.941046305978266,\n",
       " 'hugo': 6.941046305978266,\n",
       " 'confidence': 6.941046305978266,\n",
       " 'cutie': 6.941046305978266,\n",
       " 'sad': 6.941046305978266,\n",
       " 'favorite': 6.941046305978266,\n",
       " 'judith': 6.941046305978266,\n",
       " 'march': 6.941046305978266,\n",
       " 'sundays': 6.941046305978266,\n",
       " 'babysitting': 6.941046305978266,\n",
       " 'spoiled': 6.941046305978266,\n",
       " 'fest': 6.941046305978266,\n",
       " 'bonuses': 6.941046305978266,\n",
       " 'added': 6.941046305978266,\n",
       " 'frost': 6.941046305978266,\n",
       " 'mighty': 6.941046305978266,\n",
       " 'taken': 6.941046305978266,\n",
       " 'vessel': 6.941046305978266,\n",
       " 'worthless': 6.941046305978266,\n",
       " 'choked': 6.941046305978266,\n",
       " 'everywhere': 6.941046305978266,\n",
       " 'armageddon': 6.941046305978266,\n",
       " 'impact': 6.941046305978266,\n",
       " 'wave': 6.941046305978266,\n",
       " 'wants': 6.941046305978266,\n",
       " 'fanciful': 6.941046305978266,\n",
       " 'colorful': 6.941046305978266,\n",
       " 'drawings': 6.941046305978266,\n",
       " 'pencil': 6.941046305978266}"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riot see hugo weaving play sex obsessed gay real estate salesman uses clients houses trysts flaming darren tom hollander\n",
      "[[0.        0.        0.        0.        0.        0.        0.\n",
      "  0.2773501 0.        0.        0.        0.        0.2773501 0.\n",
      "  0.2773501 0.        0.        0.        0.        0.        0.\n",
      "  0.2773501 0.        0.        0.2773501 0.2773501 0.2773501 0.2773501\n",
      "  0.        0.        0.        0.        0.        0.2773501 0.\n",
      "  0.        0.        0.2773501 0.2773501 0.        0.        0.\n",
      "  0.        0.2773501 0.        0.        0.        0.        0.2773501\n",
      "  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(data[734])\n",
    "print(d[734].todense())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_3_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
